---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)

library(focal)
library(dplyr)
```

# Focal: Lenses for R

## Installation

``` r
devtools::install_github("cfhammill/focal")
```

## Intro

In typical R use we frequently perform two common operations on our data.
We `view` some piece of the data, or we `set` some piece of the data. Base
R comes with many pairs of `view` and `set` functions. For example let's
take the iris data set

```{r}
head(iris)
```

and we'll `view` the 3rd element of the `Sepal.Length` column.

```{r}
iris$Sepal.Length[3]
```

we can equivalently set the same element to a new value

```{r}
iris$Sepal.Length[3] <- 10
head(iris, 3)
```

There are some problems with having our separate `view` and `set` functions.
First is that composing these isn't easy. They can't be composed via piping

```{r}
iris %>%
  .$Sepal.Length %>%
  `[<-`(20)
```

Additionally, if you want to transform the data, not just modify it, you need
to specify your chain of accessors twice.

```{r}
iris$Sepal.Length[3] <- iris$Sepal.Length[3] * 2
head(iris, 3)
```

But there is a better way. And that way is lenses. Lenses give you all the power
of R's `view` and `set` functions and gives you composability, and a way to reduce
code duplication. Here's how we would do this with lenses. First we'll construct
a lens into the third element of `Sepal.Length`

```{r}
sepal_length3 <- index("Sepal.Length") %.% index(3)
```

Here we combined two lenses using the lens composition operator `%.%`.

Now to `view` we use the view function

```{r}
iris %>% view(sepal_length3)
```

To set we use the set function

```{r}
iris %>% set(sepal_length3, 50) %>% head(3)
```

If we want to apply a function to the data `over` the lens

```{r}
iris %>% over(sepal_length3, log) %>% head(3)
```

An additional benefit to lenses is that they are non-destructive. The
underlying data-set is never changed, so you get complete control of
when, if ever, you mutate the raw data. Now if all lenses had to
offer was more composable indexing, you might not be interested in
integrating them into your workflows. But lenses can do a lot more
than just pick and set elements in vectors. 

## More interesting lenses.

We have a lensified `dplyr::select`, let's select columns between
`Sepal.Width` and `Petal.Width` and increment them by 10.

```{r}
iris %>%
  over(select_l(Sepal.Width:Petal.Width)
     , function(x){ x + 10 }) %>%
  head(3)
```

I can imagine you saying, what good is that, I have `mutate`, well
that is certainly true. But have you ever wanted to `set` or modify
the results of a filter? Let's set all "sepal" columns
where the row number is less than 3 to zero. Let's also change
the column names to all upper case.

```{r}
iris %>%
  mutate(row_num = seq_len(n())) %>%
  set(filter_l(row_num < 3) %.%
      select_l(matches("Sepal"))
    , 0) %>%
  over(names_l, toupper) %>%
  head(3)
```

As you can see lenses can be smoothly integrated into your `tidyverse`
workflows, or your base R workflows.

## How do they work?

Next step, explain the madness.

